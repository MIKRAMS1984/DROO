{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf8TfYGDs4RwSMTGcPaZSK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MIKRAMS1984/DROO/blob/master/Replicating_DROO__Creating_DNN_for_task_offloading_decision_and_resource_allocation_using_Bisection_optimization_method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Research Gaps:\n",
        "\n",
        "\n",
        "1.   Computational complexity increases due to K quantizaion levels for relaxed binary offloading decision from DNN, although it is Adaptvie but starts from K = N, for each task, where N is the number of wireless devices, max(N = 30) and the number of input_channel_gain samples are 30K.\n",
        "2.   Acuuracy and Loss(Training Loss and Testing Loss) of DNN is not discussed in the simulation results, nor compared to a benchmark. Only a single graph is depicted, showing the exponential decay of Training Loss w.r.t. time.\n",
        "3. The convergance rate of Bisection method, used for optimal resource allocations, is slow compared to other optimization methods, such as Newton Raphson. Hence, it increases time complexity.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XExfpQlneQOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimum and Maximum values of the dataset_30.\n",
        "1.   input_h: Min = 7.271724024595681e-05,   Max = 2.977399447439086e-11. ---> Wireless channel gain\n",
        "2.   output_mode: Min = 0, Max = 1. ---> Computing mode selection\n",
        "3.   output_a: Min = 0.2924001509337536,   Max=  0.6702989331341545. ---> Time for energy harvesting\n",
        "\n",
        "4.   output_tau: Min = 0,  Max = 0.7075998490662463 ---> Time for data offloading\n",
        "\n",
        "5.   output_obj: Min = 3066213.6654264256, Max = 12440743.093937602\n",
        " ---> Weighted sum Computaoin Rate.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_iLD-z7IomLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.Mounting the google drive to display file(data_30.mat) in colab."
      ],
      "metadata": {
        "id": "ne95Co5coa9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "S=sio.loadmat('/data_30.mat') #/content/data_30.mat\n",
        "S"
      ],
      "metadata": {
        "id": "4AhKFnBhcKkw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "46bb7ba6-a0d2-4284-bb8e-56edb4e86d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3109caa36700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data_30.mat'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#/content/data_30.mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting the minimum and maximum vaules from the dataset_30(Dictionary)."
      ],
      "metadata": {
        "id": "hdLmMghyuOcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "o = sio.loadmat('/data_30.mat')['output_a']\n",
        "m = np.max(o)\n",
        "mini = np.min(o)\n",
        "m, mini, \n",
        "#/data_30.mat"
      ],
      "metadata": {
        "id": "zogLxhmmi4mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e3a758-e67c-4820-f8d4-dd41278ec710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6702989331341545, 0.2924001509337536)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Optimization.py\n",
        "\n",
        "*   Bisection method is used for **optimal** task offloading decision and **resource allocations** (time alloted for energy harvesting and time alloted for task offloading).\n",
        "*   CD Method is used as a benchmark for comparison of results.\n",
        "\n",
        "\n",
        "*   def plot_gain(): Plots the computation rate vs time frames.\n",
        "*   def bisection(): takes input channel gain, computing modes and weights of the wireless devices **as input arguments** and **returns** the maximum computation rate, optimal time for task offloading and energy harvesting.\n",
        "*   def cd_method(): used to calculate the CPU execution latency for the same dataset for comparison to the bisection method, for 10, 20, and 30 wireless devices.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jWLBdg7IslUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import optimize\n",
        "from scipy.special import lambertw\n",
        "import scipy.io as sio\n",
        "import time\n",
        "\n",
        "# Function 'gain_his' to plot Gain ratio (Computation rate) vs Learning steps.\n",
        "\n",
        "def plot_gian(gain_his):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import pandas as pd\n",
        "    import matplotlib as mpl\n",
        "\n",
        "    gain_array = np.asarray(gain_his)\n",
        "    df = pd.DataFrame(gain_his)\n",
        "\n",
        "    mpl.style.use('seaborn')\n",
        "    fig, ax = plt.subplots(figsize = (15,8))\n",
        "    rolling_intv = 20\n",
        "\n",
        "    plt.plot(np.arange(len(gain_array))+1, df.rolling(rolling_intv, min_periods=1).mean(),'b')\n",
        "    plt.fill_between(np.arange(len(gain_array)+1,df.rolling(rolling_intv, min_periods=1).min()[0], df.rolling(rolling_intv, min_periods=1).max()[0], color = 'b',alpha = 0.2))\n",
        "    plt.ylabel('Gain ratio')\n",
        "    plt.xlabel('learning steps')\n",
        "    plt.show()\n",
        "\n",
        "    # Parameters and Equations for Bisectin Method.\n",
        "    # h = gain\n",
        "    # M = m from m_list. m_list contains the binary offloading decisions solved by eq.8 and eq.9 in 1.mainPyTorch.\n",
        "    # weights is empty list.\n",
        "\n",
        "def bisection(h,M,weights=[]): #used to find avg. time for optimal solution:0.0125s\n",
        "        o=100                \n",
        "        p=3\n",
        "        u=0.7\n",
        "        eta1=((u*p)**(1.0/3))/o\n",
        "        ki=10**-26\n",
        "        eta2=u*p/10**-10\n",
        "        B=2*10**6\n",
        "        Vu=1.1\n",
        "        epsilon=B/(Vu*np.log(2))\n",
        "        x=[]\n",
        "        tau_j=a[1:] # a is energy broadcasting time for WDs\n",
        "                    # tau_j is transmit time for WDs\n",
        "        # creating M0 and M1 from M.\n",
        "        M0=np.where(M==0)[0] # Segregating the 0 and 1 binary offloading decisions.\n",
        "        M1=np.where(M==1)[0] # returns indices.\n",
        "\n",
        "        hi=np.array([h[i] for i in M0])\n",
        "        hi=np.array([h[i] for i in M1])\n",
        "\n",
        "        # if Remainder is 1 weight will be 1.5 else weight will be 1.\n",
        "\n",
        "        weights = [1.5 if i%2==1 else 1 for i in range(len(M))]\n",
        "\n",
        "        # Weights for ith and jth Wireless devices.\n",
        "\n",
        "        wi=np.array([weights[M0[i]]for i in range(len(M0))])\n",
        "        wj=np.array([weights[M1[i]]for i in range(len(M1))])\n",
        "\n",
        "        def sum_rate(x):\n",
        "            sum1=sum(wi*eta1*(hi/ki)**(1.0/3)*x[0]**(1.0/3))\n",
        "            sum2=0\n",
        "            for i in range(len(M1)):\n",
        "                sum2+=wj[i]*epsilon*x[i+1]*np.log(1+eta2*hj[i]**2*x[0]/x[i+1])\n",
        "            return sum1+sum2\n",
        "\n",
        "        def phi(v,j):\n",
        "            return 1/(-1-1/(lambertw(-1/(np.exp(1+v/wj[j]/epsilon))).real))\n",
        "\n",
        "        def p1(v):\n",
        "            p1=0\n",
        "            for j in range(len(M1)):\n",
        "                p1 +=hj[j]**2 * phi(v,j)\n",
        "            return 1/(1+p1*eta2)\n",
        "\n",
        "        def Q(v):\n",
        "            sum1 = sum(wi*eta1*(hi/ki)**(1.0/3))*p1(v)**(-2/3)/3\n",
        "            sum2 = 0\n",
        "            for j in range(len(M1)):\n",
        "                sum2 += wj[j]*hj[j]**2/(1+1/phi(v,j))\n",
        "            return sum1+sum2*epsilon*eta2-v\n",
        "\n",
        "        def tau(v,j):\n",
        "            return eta2*hj[j]**2*p1(v)*phi(v,j)\n",
        "\n",
        "        #Bisection Algorithm starts here\n",
        "\n",
        "        delta=0.005\n",
        "        UB = 99999999\n",
        "        LB = 0\n",
        "        while UB -LB > delta:\n",
        "            v = (float(UB)+LB)/2\n",
        "            if Q(v) > 0:\n",
        "                LB = v\n",
        "            else:\n",
        "                UB = v\n",
        "\n",
        "        x.append(p1(v))\n",
        "        for j in range(len(M1)):\n",
        "            x.appned(tau(v,j))\n",
        "\n",
        "        return sum_rate(x), x[0], x[1:] # Bisection returning computation rate, reward (sum_rate(x)) for r_list.\n",
        "\n",
        "        # CD Method for Comparison.\n",
        "        # CD Method Defined.\n",
        "\n",
        "        def cd_method(h):\n",
        "            N = len(h) # N = 30\n",
        "            # M0 is decision mode having 30 saclar values.(0/1)\n",
        "            M0 = np.random.randint(2,size = N) # 2 gives only binary values in the array. \n",
        "            # Input arguments: input channel gain h and offloading decision M0. \n",
        "            # bisection returns computation rate 'gain0', time for enery broadcasting 'a' and data offloading time'Tj'.\n",
        "            gain0,a,Tj = bisection(h,M0) # Calling bisecion fun. \n",
        "            g_list = [] # computaion rate for M0 (local computing)\n",
        "            M_list = [] # offloading_decisions list\n",
        "            while True:\n",
        "                for j in range(0,N): # j from 0 to 29\n",
        "                    M = np.copy(M0)\n",
        "                    M[j] = (M[j]+1)%2 # M[j] stores values 0/1 for offloading decision.\n",
        "                    gain,a,Tj = bisection(h,M) # Again calling bisection\n",
        "                    g_list.append(gain)\n",
        "                    M_list.append(M)\n",
        "                g_max = max(g_list) # Maximum reward\n",
        "                if g_max > gain0: # Comparing the rewards(compuation rate) for M and M0\n",
        "                    gain0 = g_max\n",
        "                    M0 = M_list[g_list.index(g_max)]\n",
        "                else:\n",
        "                    break\n",
        "            return gain0,M0 # Returning weighted sum computation rate for task performed locally.\n",
        "\n",
        "      #  if__name__==\"__main__\":\n",
        "            # input channel gain(h) has 10 values.\n",
        "            h=np.array([6.06020304235508*10**-6,1.10331933767028*10**-5,1.00213540309998*10**-7,1.21610610942759*10**-6,1.96138838395145*10**-6,1.71456339592966*10**-6,5.24563569673585*10**-6,5.89530717142197*10**-7,4.07769429231962*10**-6,2.88333185798682*10**-6])\n",
        "            M=np.array([1,0,0,0,1,0,0,0,0,0]) # 10 binary offloading decisions.\n",
        "#    h=np.array([1.00213540309998*10**-7,1.10331933767028*10**-5,6.06020304235508*10**-6,1.21610610942759*10**-6,1.96138838395145*10**-6,1.71456339592966*10**-6,5.24563569673585*10**-6,5.89530717142197*10**-7,4.07769429231962*10**-6,2.88333185798682*10**-6])\n",
        "#    M=np.array([0,0,1,0,1,0,0,0,0,0])\n",
        "\n",
        "    \n",
        "#    h = np.array([4.6368924987170947*10**-7,\t1.3479411763648968*10**-7,\t7.174945246007612*10**-6,\t2.5590719803595445*10**-7,\t3.3189928740379023*10**-6,\t1.2109071327755575*10**-5,\t2.394278475886022*10**-6,\t2.179121774067472*10**-6,\t5.5213902658478367*10**-8,\t2.168778154948169*10**-7,\t2.053227965874453*10**-6,\t7.002952297466865*10**-8,\t7.594077851181444*10**-8,\t7.904048961975136*10**-7,\t8.867218892023474*10**-7,\t5.886007653360979*10**-6,\t2.3470565740563855*10**-6,\t1.387049627074303*10**-7,\t3.359475870531776*10**-7,\t2.633733784949562*10**-7,\t2.189895264149453*10**-6,\t1.129177795302099*10**-5,\t1.1760290137191366*10**-6,\t1.6588656719735275*10**-7,\t1.383637788476638*10**-6,\t1.4485928387351664*10**-6,\t1.4262265958416598*10**-6, 1.1779725004265418*10**-6, 7.738218993031842*10**-7,\t4.763534225174186*10**-6])\n",
        "#    M =np.array( [0,\t0,\t1,\t0, 0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t1,\t0,\t0,\t0,\t0,\t0,\t0,\t0,\t1,])\n",
        "    \n",
        "#    time the average speed of bisection algorithm\n",
        "#    repeat = 1\n",
        "#    M =np.random.randint(2, size=(repeat,len(h)))\n",
        "#    start_time=time.time()\n",
        "#    for i in range(repeat):\n",
        "#        gain,a,Tj= bisection(h,M[i,:])\n",
        "#    total_time=time.time()-start_time\n",
        "#    print('time_cost:%s'%(total_time/repeat))\n",
        "\n",
        "            # input argurments: input channel gain h and offloading decision M0. \n",
        "            # bisection returns computation rate 'gain', time for enery broadcasting 'a' and data offloading time'Tj'.\n",
        "            gain,a,Tj = bisection(h,M) # Calling bisection fun, returning resources allocation(gain, energy broadcasting time and data transmit time).\n",
        "            print('y:%s'%gain) # Gain(Comutation rate) print\n",
        "            print('a:%s'%a)    # Energy broadcasting parameter (time alloted for energy harvesting)\n",
        "            print('Tj:%s'%Tj)  # Offloading time alloted.\n",
        "\n",
        "            # Calling CD fun.\n",
        "            # input argurments: input channel gain h. \n",
        "            # returning gain0 and computing mode selection M0 (local compute or offload)\n",
        "            gain0,M0 = cd_method(h) \n",
        "            print('max y:%s'%gain0)\n",
        "            print(M0)\n",
        "\n",
        "            K=[10, 20, 30] # Number of wireless devices.\n",
        "            N = 1000 # Iteration numbers to pick the input channel gain value from input_h.\n",
        "\n",
        "        for k in K:\n",
        "            channel = sio.loadmat('./data_%d' %int(k))['input_h'] # Input channel gains\n",
        "            gain = sio.loadmat('./data_%d' %int(k))['output_obj'] # Weighted sum computaion rate.\n",
        "\n",
        "            start_time = time.time()\n",
        "            gain_his = [] # To store computation rate\n",
        "            gain_his_ratio = [] # To get Normalized computation rate= optimal computation rate / max(optimal computation rate) for all 2^N.\n",
        "            mode_his = []\n",
        "            for i in range(N): # i from 0 to 999.\n",
        "                print(\"%0.if\"%(i/N)) # Getting integer values from floating numbers.\n",
        "\n",
        "                i_idx = i # Saving index values from 0 to 999 for N = 1000.\n",
        "\n",
        "                h = channel[i_idx,:] # h = from channel[0, :] to channel[999, :]\n",
        "\n",
        "                # Calling CD fun.\n",
        "                # input arguments: input channel gain h. \n",
        "                # returning gain0 and computing mode selection M0 (local compute or offload)\n",
        "                gain0, M0 = cd_method(h) \n",
        "\n",
        "                gain_his.append(gain0) # appending the outcome in the computation_rate list.\n",
        "                gain_his_ratio.append(gain_his[-1] / gain[i_idx][0]) # computation rate ratio.\n",
        "                mode_his.append(M0) # Appending computing mode decision in mode_his list.\n",
        "\n",
        "                total_time = time.time()-start_time # Caluclating the time for up to 30 Wireless devices.\n",
        "                print('time_cost:%s' %total_time)\n",
        "                print('average time per channel:%s'%(total_time/N))\n",
        "\n",
        "                plot_gain(gain_his_ratio) # Plotting computation rate ratio\n",
        "\n",
        "                print(\"gain/max ratio:\", sum(gain_his_ratio)/N)   "
      ],
      "metadata": {
        "id": "SnnSgwq4s6R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.DNN Parameters and Structure. \n",
        "# memoryPyTorch.py\n",
        "\n",
        "\n",
        "1.   Creates a class named MemoryDNN to intialize the hyper-parameters of DNN, define the DNN model and activation functions.\n",
        "2.   def remember(): to replace the oldest memory with the newest.\n",
        "3. def encode(): to encode the entery, input arguments are channel gain and memory size.\n",
        "4. def learn(): collecting a batch of random samples from the memory, declaring tensor size to train the model.\n",
        "5. Model training: apply optimizer, apply loss fun, clear the gradients, perform predictions, check loss, apply backward propagation to minimize the loss by updating weights and biases of DNN, again apply optimizer, calculate cost of loss function and append it to the list named 'cost_his'.\n",
        "6. def decode(): to have batch dimensions when feeding into Tensor.\n",
        "7. Perform DNN testing, while checking the quanitzation mode is order preserving 'OP'or 'KNN'.\n",
        "8. Solve eq.8 and eq.9 using def knm(): to get binary offloading decisions for k = 1 and k > 1 for 'OP' quantization method. These decisions are appended in m_list. Similarly, def knn(): to get binary offloading decisions for 'KNN' quantization method. \n",
        "9. def plot_cost(): Plots training loss vs time.\n",
        "\n"
      ],
      "metadata": {
        "id": "t7X2b34Csd_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.a.\n",
        "import torch.nn as nn\n",
        "\n",
        "class MemoryDNN:\n",
        "  def __init__(\n",
        "      self,\n",
        "      net,\n",
        "      learning_rate = 0.01,\n",
        "      training_interval = 10,\n",
        "      batch_size = 128,\n",
        "      memory_size = Memory,\n",
        "      output_graph = False,\n",
        "  ):\n",
        "    self.net = net\n",
        "    self.training_interval = training_interval\n",
        "    self.lr = learning_rate\n",
        "    self.batch_size = batch_size\n",
        "    self.memory_size = memory_size # 1000\n",
        "\n",
        "    # Stor all binary actions.\n",
        "    self.enumerate_actions = []\n",
        "\n",
        "    self.memory_counter = 1\n",
        "\n",
        "    self.cost_his = [] # Store training cost\n",
        "\n",
        "    self.memory = np.zeros((self.memory_size, self.net[0]+self.net[-1])) # 1000, 10+10\n",
        "\n",
        "    self._build_net() # Construc memory network\n",
        "\n",
        "  def _build_net(self):\n",
        "    self.model = nn.Sequential(\n",
        "      nn.Linear(self.net[0], self.net[1]),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(self.net[1], self.net[2]),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(self.net[2], self.net[3]),\n",
        "      nn.Sigmoid(),\n",
        "  )  \n",
        "    \n",
        "  def remember(self, h, m):\n",
        "    idx = self.memory_counter % self.memory_size\n",
        "    self.memory[idx, :] = np.hstack((h,m))\n",
        "\n",
        "    self.memory_counter += 1\n",
        "\n",
        "  def encode(self, h, m):\n",
        "    self.remember(h,m)\n",
        "    if self.memory_counter % self.training_interval == 0:\n",
        "      self.learn()\n",
        "\n",
        "  def learn(self):\n",
        "    if self.memory_counter > self.memory_size:\n",
        "      sample_index = np.random.choice(self.memory_size, size = self.batch_size)\n",
        "    else:\n",
        "      sample_index = np.random.choice(self.memory_counter, size = self.batch_size)\n",
        "    batch_memory = self.memory[sample_index, :]\n",
        "\n",
        "    h_train = torch.Tensor(batch_memory[:, 0:self.net[0]])\n",
        "    m_train = torch.Tensor(batch_memory[:, 0:self.net[0]:])\n",
        "\n",
        "    optimizer = optim.Adam(self.model.parameters(), lr=self.lr, betas = (0.09, 0.999), weight_decay = 0.0001)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    self.model.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    prdict = self.model(h_train)\n",
        "\n",
        "    loss = criterion(predict, m_train)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    self.cost = loss.item()\n",
        "\n",
        "    assert(self.cost > 0)\n",
        "\n",
        "    self.cost_his.append(self.cost)\n",
        "\n",
        "  def decode(self, h, k=1, mode='OP'):\n",
        "    h=torch.Tensor(h[np.newaxis,:])\n",
        "    self.model.eval()\n",
        "    m_pred=self.model(h)\n",
        "    m_pred = m_pred.dtach().numpy()\n",
        "\n",
        "    if mode == 'OP':\n",
        "      return self.knm(m_pred[0],k)\n",
        "    elif mode == 'KNN':\n",
        "      return self.knn(m_pred[0],k)\n",
        "    else:\n",
        "      print(\"The action selection must be 'OP' or 'KNN'.\")\n",
        "\n",
        "  def knm(self, m, k=1):\n",
        "    m_list = []\n",
        "    m_list.append(1*(m>0.5))\n",
        "\n",
        "    if k>1:\n",
        "      m_abs = abs(m-0.5)\n",
        "    idx_list = np.argsort(m_abs)[:k-1]\n",
        "    for i in range(k-1):\n",
        "      if m[idx_list[i]] > 0.5:\n",
        "        m_list.append(1*(m-m[idx_list[i]]>0))\n",
        "      else:\n",
        "        m_list.append(1*(m-m[idx_list[i]] >= 0))\n",
        "    return m_list\n",
        "\n",
        "  def knn(self, m, k=1):\n",
        "    if len(self.enumerate_actions) == 0:\n",
        "      import itertools\n",
        "      self.enumerate_actions=np.array(list(map(list, itertools.product([0,1], repeat=self.net[0]))))\n",
        "      sqd = ((self.enumeate_actions-m)**2).sum(1)\n",
        "      idx = np.argsort(sqd) # performs indices ascending sorting\n",
        "      return self.enumeate_actions[idx[:k]]\n",
        "\n",
        "  def plot_cost(self):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.plot(np.arange(len(self.cost_his))*self.training_interval, self.cost_his)\n",
        "    plt.ylabel('Training Loss')\n",
        "    plt.xlabel('Time Frames')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aDacgyzPsTVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Main DROO algo.\n",
        "1.   Plots the computation rate vs time frames.\n",
        "2.   Sets the hyper-parameters for DNN and loads data samples from the datasets.\n",
        "3. Splits data set as traninig dataset(80%) and testing dataset(20%).\n",
        "4. Creates an object named 'mem' for MemoryDNN, DNN consists of one input layer having 'N' number of neurons, where N is number of wireless devices. Two hidden layers having 120 and 80 neurons repectively. Finally, output layer consists of N number of neurons.\n",
        "5. ReLU activation function is used for input and hidden layers, whereas sigmoid activation function is used at output layer, to get relaxed binary offloading decision.\n",
        "6. An algorithm is written for adaptive K settings as given in the research article.\n",
        "7. mem.decode function is called to get the binary offloading decisions(m_list) by solving eq.8 and eq.9 of the research article.\n",
        "8. Bisection function is called to get the reward list(r_list) for all possible computing modes.\n",
        "9. Then encode function is called to encode the mode with largest reward(highest computation rate).\n",
        "10. The DROO training ends here. Maximum computation rate, rate ratio, adaptive k value and time are memorized to plot the graphs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dxStJJFQetKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDECwQXuExHt"
      },
      "outputs": [],
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "#from memoryPyTorch import MemoryDNN\n",
        "#from optimization import bisection\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_rate(rate_his, rolling_intv=50):\n",
        "  import matplotlib.pyplot as plt\n",
        "  import pandas as pd\n",
        "  import matplotlib as mpl\n",
        "  rate_array = np.asarray(rate_his)\n",
        "  "
      ],
      "metadata": {
        "id": "H5IyXgpfZRav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rate_array"
      ],
      "metadata": {
        "id": "-n4t4XtZaDLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(rate_his)"
      ],
      "metadata": {
        "id": "ktnsHpj2Zsgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visulaize: Normalized Computation rate vs Time Frames."
      ],
      "metadata": {
        "id": "G-LmMLtkbs6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mpl.style.use('seaborn')\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "plt.plot(np.arange(len(rate_array))+1, np.hstack(df.rolling(rolling_intv, min_periods=1).mean().values), 'b')\n",
        "plt.fill_between(len(rate_array))+1, np.hstack(df.rolling(rolling_intv, min_periods=1).min()[0].values), \n",
        "np.hstack(df.rolling(rolling_intv, min_periods=1).max()[0].values), color =  'b', alpha= 0.2)\n",
        "plt.ylabel('Normalized Computation Rate')\n",
        "plt.xlabel(\"Time Frames\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NOVl0QHXaXLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save rate_his(Computation rate) as a file."
      ],
      "metadata": {
        "id": "RZkj7_SfcLrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_text(rate_his, file_path):\n",
        "  with open(file_path, 'w') as f:\n",
        "    for rate in rate_his:\n",
        "      f.write(\"%s \\n\" %rate)\n"
      ],
      "metadata": {
        "id": "ehM4TO8acTT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Intializing the parameters fo DNN."
      ],
      "metadata": {
        "id": "UECegtKHOMg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#if__name__==\"__main__\":\n",
        "#K = max(K, K_his[-memory_size]) # memory_size = 1024\n",
        "N =10\n",
        "n = 3000\n",
        "K = N\n",
        "decoder_mode = 'OP'\n",
        "Memory = 1024\n",
        "Delta = 32\n",
        "#print(\"#user = %d, #channel = %d, K = %d, decoder = %d, Memory = %d, Delta = %d\"%(N, n, K, decoder_mode, Memory, Delta))"
      ],
      "metadata": {
        "id": "ddg99p2-OMG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Load data using sio.loadmat()"
      ],
      "metadata": {
        "id": "Vnn3TS4XeKV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n",
        "N = 5\n",
        "channel = sio.loadmat(\"data_%d\"%N)[\"input_h\"]\n",
        "channel, channel.shape, channel.dtype, channel.size"
      ],
      "metadata": {
        "id": "xHH1BaGVeOa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Rate to plot figures only, not for training DROO"
      ],
      "metadata": {
        "id": "rKhOs4O1kSVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n",
        "N = 5\n",
        "rate = sio.loadmat(\"data_%d\"%N)[\"output_obj\"]\n",
        "rate, rate.shape, rate.dtype, rate.size"
      ],
      "metadata": {
        "id": "3ZMCQp3bkdRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Changing floating values between 0 and 1 into values greater than 1, for training DROO."
      ],
      "metadata": {
        "id": "xBGd1-MjmAmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channel = channel * 1000000\n",
        "#channel,\n",
        "channel.shape, channel.dtype, channel.size"
      ],
      "metadata": {
        "id": "iOsyRtwXka9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Generating the train and test data from loaded file data_30.mat"
      ],
      "metadata": {
        "id": "e68GLyMvoy9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(channel)"
      ],
      "metadata": {
        "id": "H7rPWKh7p1lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_idx = int(0.8*len(channel))\n",
        "split_idx, \n",
        "#split_idx.shape, \n",
        "#split_idx.dtype, \n",
        "#split_idx.size"
      ],
      "metadata": {
        "id": "5zdLRrTAo-h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 30000\n",
        "num_test = min(len(channel)-split_idx, n-int(0.8*n)) #(2000, 6000)\n",
        "num_test,\n",
        "#num_test.shape"
      ],
      "metadata": {
        "id": "FZqBmECMpPa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Network Parameters.\n",
        "#To check the parameters, shape and size of a class.\n",
        "#object_name.attribute_name\n",
        "#object_name.attribute_name.shape"
      ],
      "metadata": {
        "id": "Hs9g9RaaVNvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mem.batch_size"
      ],
      "metadata": {
        "id": "AJndatGSTS6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem.memory, mem.memory.shape, "
      ],
      "metadata": {
        "id": "AWaPyHh1VwgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem.net"
      ],
      "metadata": {
        "id": "NHgbNW1DV5ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem.training_interval"
      ],
      "metadata": {
        "id": "35BmjHBFWxM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Creating 'mem' object using class named MemoryDNN using 2.a."
      ],
      "metadata": {
        "id": "jtwyFcl3M3xF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "mem = MemoryDNN(net=[N, 120, 80, N],\n",
        "                learning_rate = 0.01,\n",
        "                training_interval = 10,\n",
        "                batch_size = 128,\n",
        "                memory_size = Memory # 1024\n",
        "                )\n",
        "start_time = time.time()\n",
        "\n"
      ],
      "metadata": {
        "id": "HXXnf7kIsTqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.rate_his used to plot the Normalized computation rate vs Time Frames."
      ],
      "metadata": {
        "id": "eyRxR8RNs6gB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rate_his = []\n",
        "rate_his_ratio = []\n",
        "mode_his = []\n",
        "k_idx_his = []\n",
        "K_his = []"
      ],
      "metadata": {
        "id": "4ADMdkSpvlKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Implementing Adaptive K parameters."
      ],
      "metadata": {
        "id": "v2wXlvjevchM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Delta = 32\n",
        "for i in range(n):\n",
        "  if i % (n//10) == 0:\n",
        "    print(\" % 0.1f \"% (i/n))\n",
        "    if i > 0 and i % Delta == 0:\n",
        "      if Delta > 1: \n",
        "        max_k = max(k_idx_his[-Delta:-1]) + 1\n",
        "      else:\n",
        "        max_k = k_idx_his[-1]+1\n",
        "      K = min(max_k+1, N)"
      ],
      "metadata": {
        "id": "YNetGZT5w6By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K"
      ],
      "metadata": {
        "id": "aRltGtUpxK_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Training and Testing"
      ],
      "metadata": {
        "id": "9SpyCBBcxdQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if i < n-num_test:\n",
        "  i_idx = i % split_idx # training\n",
        "else:\n",
        "  i_idx = i - n + num_test + split_idx # testing\n",
        "\n"
      ],
      "metadata": {
        "id": "8Ujf12NtxUmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = channel[i_idx, :]\n",
        "h, h.shape, h.size"
      ],
      "metadata": {
        "id": "PkhFfTpmxz-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Decoding Fun"
      ],
      "metadata": {
        "id": "m_YK2YDKa9mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(self, h, k=1, mode='OP'):\n",
        "  h=torch.Tensor(h[np.newaxis,:])\n",
        "  self.model.eval()\n",
        "  m_pred=self.model(h)\n",
        "  m_pred = m_pred.dtach().numpy()\n",
        "\n",
        "  if mode == 'OP':\n",
        "    return self.knm(m_pred[0],k)\n",
        "  elif mode == 'KNN':\n",
        "    return self.knn(m_pred[0],k)\n",
        "  else:\n",
        "    print(\"The action selection must be 'OP' or 'KNN'.\")"
      ],
      "metadata": {
        "id": "cznUITFX9Ve0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ak8AGZDJnaBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Decoding using \"OP (Order-Preserving Quantization)\" or \"KNN( Kth Nearest Neighbour Quantization Method.)\""
      ],
      "metadata": {
        "id": "t_urbmPYyDT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "m_list = mem.decode(h, K, decoder_mode)\n",
        "r_list = [] # Reward List\n",
        "for m in m_list:\n",
        "  r_list.append(bisection(h/1000000, m)[0])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QjDaCO0fyNKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode the mode with largest reward"
      ],
      "metadata": {
        "id": "Hnj_XlnW8N6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mem.encode(h, m_list[np.argmax(r_list)])\n"
      ],
      "metadata": {
        "id": "xh2gUnoZ8Qt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The main code for DROO training ends here"
      ],
      "metadata": {
        "id": "OnSBRRcn8c6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics for Visulaization, Memorizing the largest reward"
      ],
      "metadata": {
        "id": "ZHf2cyTc8l4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rate_his.append(np.max(r_list))\n",
        "rate_his_ratio.append(rate_his[-1] / rate[i_idx[0]])\n"
      ],
      "metadata": {
        "id": "Sq8NBwmf8vML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Recording the index of largest reward"
      ],
      "metadata": {
        "id": "ifULV3_G9Blp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_idx_his.append(np.argmax(r_list))"
      ],
      "metadata": {
        "id": "bM-bcLh39Fqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Record K in case of adaptive K"
      ],
      "metadata": {
        "id": "jLh_3WXc9RF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K_his.append(K)\n",
        "mode_his.append(m_list[np.argmax[r_list]])\n"
      ],
      "metadata": {
        "id": "xpHeuHkq9Vkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Simulation time"
      ],
      "metadata": {
        "id": "CFtI9GpO9j1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_time = time.time()-start_time\n",
        "mem.plot_cost() # Fun. call to plot cost\n",
        "plot_rate(rate_his_ratio)"
      ],
      "metadata": {
        "id": "thHAruM19nls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize: Average Normalized Compuatation Rate vs Time Consumed "
      ],
      "metadata": {
        "id": "Fpp9MAT799d7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Averaged normalized computation rate:\", sum(rate_his_ratio[-num_test:-1])/num_test)\n",
        "print(\"Total time consumed: %s\" %total_time)\n",
        "print(\"Average time per channel: %s\" %(total_time/n))"
      ],
      "metadata": {
        "id": "M40jTH3P-KWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving data into text files"
      ],
      "metadata": {
        "id": "BJwz9qwB-r7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_to_text(k_idx_his, \"k_idx_his.txt\")\n",
        "save_to_text(K_his, \"K_his.txt\")\n",
        "save_to_text(mem.cost_his, \"mem.cost_his.txt\")\n",
        "save_to_text(rate_his_ratio, \"rate_his_ratio.txt\")\n",
        "save_to_text(mode_his, \"mode_his.txt\")"
      ],
      "metadata": {
        "id": "RZQdpClQ-waV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. MemoryPyTorch.py to create DNN.\n",
        "1. to get rate_his"
      ],
      "metadata": {
        "id": "KvMs_5HZf2tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from__future__import print_function\n",
        "import torch \n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "3-ucDvibf1fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self.memory"
      ],
      "metadata": {
        "id": "C4mMlgYTxQD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stor all binary actions.\n",
        "self.enumerate_actions = []"
      ],
      "metadata": {
        "id": "W0Wn3-aOt1eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self.memory_counter = []"
      ],
      "metadata": {
        "id": "td5YNxgHv_l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self.cost_his = []"
      ],
      "metadata": {
        "id": "rtQKhwxuwKAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Intialize zero memory[h,m]\n",
        "self.memory = np.zeros((self.memory_size, self.net[0]+self.net[-1]))"
      ],
      "metadata": {
        "id": "aLI2j8tqwOAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self._build_net()\n"
      ],
      "metadata": {
        "id": "cem2_kTqsb2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _build_net(self):\n",
        "  self.model = nn.Sequential(\n",
        "      nn.Linear(self.net[0], self.net[1]),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(self.net[1], self.net[2]),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(self.net[2], self.net[3]),\n",
        "      nn.Sigmoid(),\n",
        "  )  \n"
      ],
      "metadata": {
        "id": "rAM-gKg1wy0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remember(self, h, m):\n",
        "  idx = self.memory_counter % self.memory_size\n",
        "  self.memory[idx, :] = np.hstack((h,m))\n",
        "\n",
        "  self.memory_counter += 1\n",
        " "
      ],
      "metadata": {
        "id": "-dgYlv3KyXRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(self, h, m):\n",
        "  self.remember(h,m)\n",
        "  if self.memory_counter % self.training_interval == 0:\n",
        "    self.learn()\n",
        "\n"
      ],
      "metadata": {
        "id": "Lxt1l0aly7iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learn(self):\n",
        "  if self.memory_counter > self.memory_size:\n",
        "    sample_index = np.random.choice(self.memory_size, size = self.batch_size)\n",
        "  else:\n",
        "    sample_index = np.random.choice(self.memory_counter, size = self.batch_size)\n",
        "  batch_memory = self.memory[sample_index, :]\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k_JNgorAzn7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_train = torch.Tensor(batch_memory[:, 0:self.net[0]])\n",
        "m_train = torch.Tensor(batch_memory[:, 0:self.net[0]:])\n",
        "\n"
      ],
      "metadata": {
        "id": "BRN4_eSP0bkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the DNN"
      ],
      "metadata": {
        "id": "ea6dTwy803uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "optimizer = optim.Adam(self.model.parameters(), lr=self.lr, betas = (0.09, 0.999), weight_decay = 0.0001)"
      ],
      "metadata": {
        "id": "2rXWdYuO02RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "vah4Kfd71fY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self.model.train()"
      ],
      "metadata": {
        "id": "i_02zI8D1k2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "0gKD_8rB8j05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prdict = self.model(h_train)"
      ],
      "metadata": {
        "id": "iEI8E1X18ouS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criterion(predict, m_train)"
      ],
      "metadata": {
        "id": "YvFqZZLg8_1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "FCTubQfU9EhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()"
      ],
      "metadata": {
        "id": "tcv0G__Q9IFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sel.cost = loss.item()"
      ],
      "metadata": {
        "id": "_Sf6Z-279LIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert(self.cost>0)"
      ],
      "metadata": {
        "id": "b9bCNzxj9N5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self.cost_his.append(self.cost)"
      ],
      "metadata": {
        "id": "77-KdRQf9Ri2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing equation 8 and 9, to get k binary offloading decisions."
      ],
      "metadata": {
        "id": "QeeikyJ2_9cN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knm(self, m, k=1):\n",
        "  m_list = []\n",
        "  m_list.append(1*(m>0.5))\n",
        "\n",
        "  if k>1:\n",
        "    m_abs = abs(m-0.5)\n",
        "    idx_list = np.argsort(m_abs)[:k-1]\n",
        "    for i in range(k-1):\n",
        "      if m[idx_list[i]] > 0.5:\n",
        "        m_list.append(1*(m-m[idx_list[i]]>0))\n",
        "      else:\n",
        "        m_list.append(1*(m-m[idx_list[i]] >= 0))\n",
        "\n",
        "  return m_list\n"
      ],
      "metadata": {
        "id": "pHx-O9-0_rmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating L2 Norm using Itertools"
      ],
      "metadata": {
        "id": "1zzApPiAFF4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn(self, m, k=1):\n",
        "  if len(self.enumerate_actions) == 0:\n",
        "    import itertools\n",
        "    self.enumerate_actions=np.array(list(map(list, itertools.product([0,1], repeat=self.net[0]))))\n",
        "    sqd = ((self.enumeate_actions-m)**2).sum(1)\n",
        "    idx = np.argsort(sqd) # performs indices ascending sorting\n",
        "    return self.enumeate_actions[idx[:k]]"
      ],
      "metadata": {
        "id": "YA-fnCjlBJ4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize: Plotting Training Loss vs Time Frames."
      ],
      "metadata": {
        "id": "VneG5EqmKCRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cost(self):\n",
        "  import matplotlib.pyplot as plt\n",
        "  plt.plot(np.arange(len(self.cost_his))*self.training_interval, self.cost_his)\n",
        "  plt.ylabel('Training Loss')\n",
        "  plot.xlabel('Time Frames')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "djkWZZu2KKoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_rate(rate_his, rolling_intv=50):\n",
        "  import matplotlib.pylot as plt\n",
        "  import pandas as pd\n",
        "  import matlplotlib as mpl\n",
        "  rate_array = np.asarray(rate_his)"
      ],
      "metadata": {
        "id": "NMi8TPjwfEKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(rae_his)"
      ],
      "metadata": {
        "id": "5HX1S0yOfrnf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}